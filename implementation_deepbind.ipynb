{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "x<h1 style=\"margin-bottom:0\"><center>DI 504: Fundementals of Deep Learning</center></h1>\n",
    "<h2 style=\"margin-top:0\"><center> Project - Implementation of DeepBind Model </center></h2>\n",
    "<h3 style=\"margin-top:0\"><center>Hüseyin Hilmi Kılınç </center></h3>\n",
    "<h3 style=\"margin-top:0\"><center> 2239275 </center></h3>\n",
    "<h4 style=\"margin-top:0\"><center><b>Due by June 20th, Friday at 23:59</b></center></h4>\n",
    "<br>\n",
    "\n",
    "### Problem Definition\n"
   ],
   "id": "f534403a15131fec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing necessary libraries",
   "id": "4365801455f43c1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-20T12:07:39.763360Z",
     "start_time": "2025-06-20T12:07:39.760908Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import gzip\n",
    "from scipy.stats import bernoulli\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gzip, csv, random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc as calc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "# 1) Select device: MPS if available, else CPU\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Falling back to CPU\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS device\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I. Utility Functions\n",
   "id": "ff1a6105edabc057"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:04:58.161165Z",
     "start_time": "2025-06-20T12:04:58.158630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bases='ACGT' #DNA bases\n",
    "basesRNA='ACGU'#RNA bases (but it is unnecessary for this project)\n",
    "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
    "reverse_mode= False # If reverse_complemet_mode is set to True, each original input sequence is duplicated with its reverse complement to account for strand ambiguity in DNA (i.e., both ATGC... and its reverse-complement GCAT... could potentially bind the TF)."
   ],
   "id": "9f880d6eec66c06c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Sequence Padding and One-Hot Encoding DNA**\n",
    "Prepares an input DNA sequence for convolutional motif scanning by:\n",
    "\n",
    "\t1.\tPadding the sequence at both ends so that a filter of length motif_len can slide fully over every original position.\n",
    "\t2.\tConverting each position into either a one-hot encoding (exact match → 1/0) or, for padding/unknowns (N), a uniform probability (0.25 for each base)."
   ],
   "id": "a97a1df8ef4957bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:04:59.398382Z",
     "start_time": "2025-06-20T12:04:59.394776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def padded_onehot_seq(sequence, motif_len, kind='DNA'):\n",
    "    rows = len(sequence) + 2 * motif_len - 2  # total padded length\n",
    "    S = np.empty([rows, 4])  # matrix of shape (rows, 4) to store one-hot or probabilistic encodings\n",
    "    base = bases if kind == 'DNA' else basesRNA  # choose ACGT or ACGU (for RNA composition)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(4):\n",
    "            if i - motif_len + 1 < len(sequence) and sequence[i - motif_len + 1] == 'N' \\\n",
    "               or i < motif_len - 1 or i > len(sequence) + motif_len - 2:\n",
    "                # Unknown base or in the padding region\n",
    "                S[i, j] = np.float32(0.25)  # equal probability for A, C, G, T\n",
    "            elif sequence[i - motif_len + 1] == base[j]:\n",
    "                S[i, j] = np.float32(1)  # one-hot for matching base\n",
    "            else:\n",
    "                S[i, j] = np.float32(0)  # not the correct base\n",
    "\n",
    "    return np.transpose(S)  # transpose to shape (4, sequence length)\n",
    "example_padding = padded_onehot_seq(\"ATNGCA\",motif_len=3) # N means unknown base from genomic sequence\n",
    "print(\"A toy sequence example One-Hot encoding with padding:\\n\", example_padding)"
   ],
   "id": "9f1de2c553a3e8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A toy sequence example One-Hot encoding with padding:\n",
      " [[0.25 0.25 1.   0.   0.25 0.   0.   1.   0.25 0.25]\n",
      " [0.25 0.25 0.   0.   0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.25 0.25 0.   0.   0.25 1.   0.   0.   0.25 0.25]\n",
      " [0.25 0.25 0.   1.   0.25 0.   0.   0.   0.25 0.25]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Sequence Manipulation Utilities\n",
    "\n",
    "* dinucshuffle(sequence) :\n",
    "Splits the input into consecutive dinucleotides, shuffles those pairs at random (so you still get two‐base blocks, though not true overlapping dinuc preservation), and reassembles them into a new sequence. Use for generating simple negative controls.\n",
    "\n",
    "* reverse_complement(seq) :\n",
    "Maps each base to its Watson–Crick complement (A⇄T, C⇄G, N→N) and reverses the input string and then applies complement, yielding the classic reverse‐complement sequence used in DNA motif analyses."
   ],
   "id": "2134fc296f53f1f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:05:01.061201Z",
     "start_time": "2025-06-20T12:05:01.057900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dinucleotide-preserving shuffle\n",
    "def dinuc_shuffle(sequence):\n",
    "    di_mers = [sequence[i:i+2] for i in range(0, len(sequence), 2)]  # split into dinucleotides\n",
    "    random.shuffle(di_mers) # shuffle preserving dinucleotide composition\n",
    "    shuffled_seq = ''.join(di_mers)  # reassemble into a sequence\n",
    "    return shuffled_seq\n",
    "\n",
    "# Mapping reverse complement sequence input\n",
    "def reverse_complement(seq):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}  # standard Watson-Crick base pairing\n",
    "    seq = list(seq)\n",
    "    seq.reverse()\n",
    "    complseq = [complement[base] for base in seq]  # replace each base with its complement\n",
    "    return ''.join(complseq)\n"
   ],
   "id": "33999a473c29ec26",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### II. Data Loading with Augmentation and 3-Fold Splitting\n",
   "id": "3c9f1d93683382d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:05:02.485057Z",
     "start_time": "2025-06-20T12:05:02.479616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChIP_exp:\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename: str,\n",
    "        motif_len: int = 24,\n",
    "        reverse_complement_mode: bool = False,\n",
    "        n_splits: int = 3,\n",
    "        random_seed: int = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        - filename: path to gzipped TSV with sequence in column 3 (0-based index 2)\n",
    "        - motif_len: filter length for seqtopad\n",
    "        - reverse_complement_mode: if True, also include reverse-complement augmentations\n",
    "        - n_splits: number of cross-validation folds (default 3)\n",
    "        - random_seed: seed for reproducible shuffling/splits\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.motif_len = motif_len\n",
    "        self.rev_mode = reverse_complement_mode # For Data augmentation\n",
    "        self.n_splits = n_splits\n",
    "        self.seed = random_seed\n",
    "\n",
    "    def openFile(self):\n",
    "        # 1) Read and augment\n",
    "        data = []\n",
    "        with gzip.open(self.filename, 'rt') as fp:\n",
    "            reader = csv.reader(fp, delimiter='\\t')\n",
    "            next(reader)  # skip header\n",
    "            for row in reader:\n",
    "                positive_seq = row[2] # third column includes DNA sequence\n",
    "                onehot_encoded_positive_seq = padded_onehot_seq(positive_seq, self.motif_len)\n",
    "                # always include the real sequence as positive\n",
    "                data.append((onehot_encoded_positive_seq, 1)) # One-hot encoded positive sample (labeled as 1)\n",
    "\n",
    "                # optionally include its reverse complement as also positive (For data augmentation part)\n",
    "                if self.rev_mode:\n",
    "                    rc_pos_seq = reverse_complement(positive_seq)\n",
    "                    one_hot_encoded_rc_pos_seq = padded_onehot_seq(rc_pos_seq, self.motif_len)\n",
    "                    data.append((one_hot_encoded_rc_pos_seq, 1))\n",
    "\n",
    "                # add shuffled negatives (with or without reversing)\n",
    "                # shuffle on the raw and on its reverse if rev_mode\n",
    "                negative_seq = dinuc_shuffle(positive_seq)\n",
    "                one_hot_encoded_negative_seq = padded_onehot_seq(negative_seq, self.motif_len)\n",
    "                data.append((one_hot_encoded_negative_seq, 0)) # One-hot encoded negative (dinucleotide shuffled - labeled as 0)\n",
    "                if self.rev_mode: # (also For data augmentation part)\n",
    "                    rc_neq_seq = dinuc_shuffle(reverse_complement(positive_seq))\n",
    "                    one_hot_encoded_rc_neqative_seq = padded_onehot_seq(rc_neq_seq, self.motif_len)\n",
    "                    data.append((one_hot_encoded_rc_neqative_seq, 0))\n",
    "\n",
    "        # 3) Build 3-fold splits using KFold\n",
    "        # kf = KFold(n_splits=self.n_splits, shuffle=False, random_state=None)\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n",
    "        splits = []\n",
    "        indices = list(range(len(data)))\n",
    "        for train_idx, valid_idx in kf.split(indices):\n",
    "            train = [data[i] for i in train_idx]\n",
    "            valid = [data[i] for i in valid_idx]\n",
    "            splits.append((train, valid))\n",
    "\n",
    "        # 4) Return list of folds plus the full dataset\n",
    "        #    splits[0] = (fold1_train, fold1_valid), etc.\n",
    "        return splits, data\n",
    "\n",
    "    def openFile_test(self):\n",
    "        test_dataset=[]\n",
    "        with gzip.open(self.filename, 'rt') as data:\n",
    "            next(data)\n",
    "            reader = csv.reader(data,delimiter='\\t')\n",
    "            if not self.rev_mode:\n",
    "                for row in reader:\n",
    "                    pos_neg_seq_test = row[2]\n",
    "                    label_test = row[3]\n",
    "                    one_hot_encoded_seq = padded_onehot_seq(pos_neg_seq_test,self.motif_len)\n",
    "                    test_dataset.append((one_hot_encoded_seq,label_test))\n",
    "            else:\n",
    "                for row in reader:\n",
    "                    seq = row[2]\n",
    "                    label_test = int(row[3])\n",
    "                    one_hot_encoded_seq = padded_onehot_seq(seq, self.motif_len)\n",
    "                    test_dataset.append((one_hot_encoded_seq, label_test))\n",
    "                    one_hot_encoded_rc_seq = padded_onehot_seq(reverse_complement(seq), self.motif_len)\n",
    "                    test_dataset.append((one_hot_encoded_rc_seq, label_test))\n",
    "        return test_dataset"
   ],
   "id": "c4ad054f75cb4c7b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:12:00.801795Z",
     "start_time": "2025-06-20T12:12:00.784114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_raw_sequences = pd.read_csv(\"encode/SP1_GM12878_SP1_HudsonAlpha_AC.seq.gz\",sep='\\t')\n",
    "print(\"Example Experimental Raw Dataset:\\n\", raw_sequences)"
   ],
   "id": "25ca5975d528be91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Experimental Raw Dataset:\n",
      "       FoldID         EventID  \\\n",
      "0          A  seq_00001_peak   \n",
      "1          A  seq_00003_peak   \n",
      "2          A  seq_00005_peak   \n",
      "3          A  seq_00007_peak   \n",
      "4          A  seq_00009_peak   \n",
      "...      ...             ...   \n",
      "17743      A  seq_18244_peak   \n",
      "17744      A  seq_18245_peak   \n",
      "17745      A  seq_18246_peak   \n",
      "17746      A  seq_18247_peak   \n",
      "17747      A  seq_18248_peak   \n",
      "\n",
      "                                                     seq  Bound  \n",
      "0      GTATCTGATTGGCTGCTAGCAGGCAGAGAAGGTATCTGATTGGCTG...      1  \n",
      "1      ATCATTCTCTGTGCTGCTTCTACAGGTTAATACACGCTGATCTTCT...      1  \n",
      "2      CGGCCTCGGCTTCACGTCTATTGGAAGGAACCGCTGTCTATCTCTA...      1  \n",
      "3      TATCACGTCGATCACTGGTTCTTTCGATCTGTCGCTCAGCTAAAGA...      1  \n",
      "4      CCGGCCTCCGGTAGGTTGCAACCCATGTCACTCAGGATGAATGGCT...      1  \n",
      "...                                                  ...    ...  \n",
      "17743  GGGGGTGGTCTTGTGGGACTGAGCCCTGAACCTGTGGTTTCTGAGG...      1  \n",
      "17744  GATCCCACGCTGCGCTTTCGCCACGTCCTGACGGCTGCCCGATAAA...      1  \n",
      "17745  GGCCTACGTCAGCCGCGGGAAATTCCCCTCCCGCCAGGCTGCTCGC...      1  \n",
      "17746  ACGCACACACGCACCCATGCTCACACACACACCACACAAGCATGCT...      1  \n",
      "17747  GTGGCTAGAAGCTGGTTTGCAGTAGGTGGAGAACAAACAGGGAATG...      1  \n",
      "\n",
      "[17748 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:12:43.627756Z",
     "start_time": "2025-06-20T12:12:41.681221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chip_seq = ChIP_exp(\"encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz\") # Importing TF-ChIP-seq experimental sequence data\n",
    "splits,alldataset = chip_seq.openFile()\n",
    "\n",
    "print(\"Train splits:\",len(splits[0][0]), len(splits[1][0]), len(splits[2][0])) # train sets\n",
    "print(\"Validation splits:\", len(splits[0][1]), len(splits[1][1]), len(splits[2][1])) # validation sets\n",
    "print(\"Full dataset size:\",len(alldataset))\n",
    "print(\"Train shape:\",splits[0][0][0][0].shape) #  Example train shape (4, 147) means 4 channels (A/C/G/T) by 147 positions (23 padding bases on each side of the 101-bp sequence)."
   ],
   "id": "420905396502f269",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train splits: 6778 6779 6779\n",
      "Validation splits: 3390 3389 3389\n",
      "Full dataset size: 10168\n",
      "Train shape: (4, 147)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:12:45.220621Z",
     "start_time": "2025-06-20T12:12:45.217330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a custom Dataset wrapping ChIP-seq feature/label pairs\n",
    "class chipseq_dataset(Dataset):\n",
    "\n",
    "    def __init__(self,xy=None):\n",
    "        self.x_data=np.asarray([el[0] for el in xy],dtype=np.float32) # Stack feature arrays into a NumPy array and cast to float32\n",
    "        self.y_data =np.asarray([el[1] for el in xy ],dtype=np.float32)  # Stack labels into a NumPy array and cast to float32\n",
    "        # Convert NumPy arrays to a PyTorch tensor\n",
    "        self.x_data = torch.from_numpy(self.x_data)\n",
    "        self.y_data = torch.from_numpy(self.y_data).view(-1, 1) # reshaping y_data\n",
    "        self.len=len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index] # Return the feature tensor and its corresponding label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len # Return the total number of samples in the dataset"
   ],
   "id": "45a8577da2084f9d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:12:47.188482Z",
     "start_time": "2025-06-20T12:12:47.151940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare lists to hold DataLoaders\n",
    "train_dataloader = []\n",
    "valid_dataloader = []\n",
    "batch_size=64 # fixed batch size\n",
    "\n",
    "# Iterate over each fold’s (train, valid) pair\n",
    "for fold_idx, (train_xy, valid_xy) in enumerate(splits, start=1):\n",
    "    # Wrap the raw (features, labels) lists into your dataset\n",
    "    train_ds = chipseq_dataset(train_xy)\n",
    "    valid_ds = chipseq_dataset(valid_xy)\n",
    "\n",
    "    # Create DataLoader\n",
    "    # shuffle training folds unless in reverse-complement mode\n",
    "    train_splitloader = DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=not reverse_mode\n",
    "    )\n",
    "    # validation loaders never shuffle\n",
    "    valid_splitloader = DataLoader(\n",
    "        dataset=valid_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    train_dataloader.append(train_splitloader)\n",
    "    valid_dataloader.append(valid_splitloader)\n",
    "\n",
    "# Optionally, build a DataLoader over the full dataset too:\n",
    "full_ds     = chipseq_dataset(alldataset)\n",
    "full_loader = DataLoader(full_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Now we can index:\n",
    "#   train_loaders[0], valid_loaders[0]  →  fold 1\n",
    "#   train_loaders[1], valid_loaders[1]  →  fold 2\n",
    "#   train_loaders[2], valid_loaders[2]  →  fold 3"
   ],
   "id": "9fa02064906611c8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### III. DeepBind Model Architecture Definition\n",
    "\n",
    "This section defines the core DeepBind-inspired convolutional neural network (`ConvNet`) used to predict transcription factor binding from DNA sequences. The model includes:\n",
    "\n",
    "- **1D Convolutional Filters (`wConv`)**: These detect motifs across the input sequence (encoded as 4-channel one-hot vectors).\n",
    "- **Rectification Layer (`wRect`)**: Acts as a learnable threshold applied before the ReLU activation.\n",
    "- **Pooling Options**: Global max pooling or combined max+average pooling (`poolType`), allowing different motif summarization strategies.\n",
    "- **Fully Connected Layers**: Either a single-layer output (`nohidden`) or a hidden layer with 32 ReLU units (`hidden`), controlled by the `neuType` flag.\n",
    "- **Dropout Regularization**: Applied optionally during training to reduce overfitting.\n",
    "- **Reverse-Complement Handling**: If `reverse_mode` is enabled, the model takes both forward and reverse DNA strands and picks the one with the stronger predicted binding signal.\n",
    "- **Custom Initialization**: The weights and biases are initialized from normal distributions with tunable standard deviations (`sigmaConv`, `sigmaNeu`), and L2 regularization terms (`beta1`, `beta2`, `beta3`) are added to the loss to encourage simpler models.\n",
    "\n",
    "The model supports two forward paths:\n",
    "- `forward_pass`: Applies conv → ReLU → pool → FC(+dropout).\n",
    "- `forward`: Handles optional strand-aware inference using paired inputs."
   ],
   "id": "8b22550a1cf806e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:12:51.274430Z",
     "start_time": "2025-06-20T12:12:51.263779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Randomly sampled during the hyperparameter tuning phase\n",
    "def logsampler(a,b):\n",
    "        x=np.random.uniform(low=0,high=1)\n",
    "        y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
    "        return y\n",
    "\n",
    "def sqrtsampler(a,b):\n",
    "\n",
    "        x=np.random.uniform(low=0,high=1)\n",
    "        y=(b-a)*math.sqrt(x)+a\n",
    "        return y\n",
    "\n",
    "# input of shape(batch_size,inp_chan,iW) - From your earlier print: (4, 147) → so for one sample, it’s 4 channels × 147 length\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, nummotif,motiflen,poolType,neuType,mode,dropprob,\n",
    "                 learning_rate,momentum_rate,sigmaConv,sigmaNeu,\n",
    "                 beta1,beta2,beta3,reverse_complemet_mode=reverse_mode):\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Store meta-parameters\n",
    "        self.poolType=poolType # pooling: 'max' or 'maxavg'\n",
    "        self.neuType=neuType # hidden layer or not\n",
    "        self.mode=mode  # 'training' or 'testing'\n",
    "        self.reverse_complemet_mode=reverse_complemet_mode\n",
    "        self.dropprob=dropprob\n",
    "        self.learning_rate=learning_rate\n",
    "        self.momentum_rate=momentum_rate\n",
    "        self.sigmaConv=sigmaConv  # std dev for conv weight init\n",
    "        self.sigmaNeu=sigmaNeu # std dev for fc layer init\n",
    "        self.beta1, self.beta2, self.beta3 = beta1, beta2, beta3  # for regularization\n",
    "        # Convolutional filters (motif detectors)\n",
    "        self.wConv=torch.randn(nummotif,4,motiflen).to(device) # (16,4,24) -> nummotif(kernels), 4(input channels since 4 DNA composition), motiflen (how many consecutive bases the filter spans)\n",
    "        torch.nn.init.normal_(self.wConv,mean=0,std=self.sigmaConv)\n",
    "        self.wConv.requires_grad=True\n",
    "\n",
    "        # Rectification bias (threshold before ReLU)\n",
    "        self.wRect=torch.randn(nummotif).to(device)\n",
    "        torch.nn.init.normal_(self.wRect)\n",
    "        self.wRect=-self.wRect # Negated threshold bias\n",
    "        self.wRect.requires_grad=True\n",
    "\n",
    "        # If no hidden layer: output directly from pooled vector\n",
    "        if neuType=='nohidden':\n",
    "\n",
    "            if poolType=='maxavg':\n",
    "                self.wNeu=torch.randn(2 * nummotif,1).to(device)\n",
    "            else:\n",
    "                self.wNeu=torch.randn(nummotif,1).to(device)\n",
    "            self.wNeuBias=torch.randn(1).to(device)\n",
    "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
    "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
    "        # With hidden layer (32 ReLU units)\n",
    "        else:\n",
    "            if poolType=='maxavg':\n",
    "                self.wHidden=torch.randn(2 * nummotif,32).to(device)\n",
    "            else:\n",
    "\n",
    "                self.wHidden=torch.randn(nummotif,32).to(device)\n",
    "            self.wNeu=torch.randn(32,1).to(device)\n",
    "            self.wNeuBias=torch.randn(1).to(device)\n",
    "            self.wHiddenBias=torch.randn(32).to(device)\n",
    "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
    "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
    "            torch.nn.init.normal_(self.wHidden,mean=0,std=0.3)\n",
    "            torch.nn.init.normal_(self.wHiddenBias,mean=0,std=0.3)\n",
    "\n",
    "\n",
    "            self.wHidden.requires_grad=True\n",
    "            self.wHiddenBias.requires_grad=True\n",
    "\n",
    "        self.wNeu.requires_grad=True\n",
    "        self.wNeuBias.requires_grad=True\n",
    "\n",
    "    # Handle reverse complements (for pairwise inputs)\n",
    "    def divide_two_tensors(self,x):\n",
    "        # Input has shape (batch*2, channels, length) → separate forward and reverse strands\n",
    "        l=torch.unbind(x)\n",
    "        list1=[l[2*i] for i in range(int(x.shape[0]/2))]\n",
    "        list2=[l[2*i+1] for i in range(int(x.shape[0]/2))]\n",
    "        x1=torch.stack(list1,0)\n",
    "        x2=torch.stack(list2,0)\n",
    "        return x1,x2\n",
    "\n",
    "    # One pass through the conv + pool + FC layers\n",
    "    def forward_pass(self,x,mask=None,use_mask=False): # input of shape(batch_size, 4, sequence_length)\n",
    "\n",
    "        conv=F.conv1d(x, self.wConv, bias=self.wRect, stride=1, padding=0)   # 1D convolution across sequence, lets say seq length= 147, ((147-24)/1 +1 = 124 )\n",
    "        rect=conv.clamp(min=0) # Apply ReLU (rectification stage) #\n",
    "        maxPool, _ = torch.max(rect, dim=2)  # Global max pooling, for each of the 16 filters, keep only the highest activation score across the 124 positions\n",
    "        if self.poolType=='maxavg': # Optional average pooling\n",
    "            avgPool= torch.mean(rect, dim=2)\n",
    "            pool=torch.cat((maxPool, avgPool), 1)\n",
    "        else:\n",
    "            pool=maxPool\n",
    "\n",
    "        # Apply Fully Connected Layers\n",
    "        if(self.neuType=='nohidden'):\n",
    "            if self.mode=='training':\n",
    "                if  not use_mask:\n",
    "                  mask=bernoulli.rvs(self.dropprob, size=len(pool[0]))\n",
    "                  mask=torch.from_numpy(mask).float().to(device)\n",
    "                pooldrop=pool*mask\n",
    "                out=pooldrop @ self.wNeu # Matrix Multiplication\n",
    "                out.add_(self.wNeuBias)\n",
    "            else:\n",
    "                out=self.dropprob*(pool @ self.wNeu)\n",
    "                out.add_(self.wNeuBias)\n",
    "        else:\n",
    "            hid=pool @ self.wHidden\n",
    "            hid.add_(self.wHiddenBias)\n",
    "            hid=hid.clamp(min=0)\n",
    "            if self.mode=='training':\n",
    "                if  not use_mask:\n",
    "                  mask=bernoulli.rvs(self.dropprob, size=len(hid[0]))\n",
    "                  mask=torch.from_numpy(mask).float().to(device)\n",
    "                hiddrop=hid*mask\n",
    "                out=self.dropprob*(hid @ self.wNeu)\n",
    "                out.add_(self.wNeuBias)\n",
    "            else:\n",
    "                out=self.dropprob*(hid @ self.wNeu)\n",
    "                out.add_(self.wNeuBias)\n",
    "        return out,mask\n",
    "\n",
    "    # Full Forward Pass (Handles strand ambiguity)\n",
    "    def forward(self, x):\n",
    "\n",
    "        if not  self.reverse_complemet_mode:\n",
    "            out,_=self.forward_pass(x)\n",
    "\n",
    "        else:\n",
    "            # Forward and reverse strands are split in pairs\n",
    "            x1,x2=self.divide_two_tensors(x)\n",
    "            out1,mask=self.forward_pass(x1)\n",
    "            out2,_=self.forward_pass(x2,mask,True)\n",
    "            out=torch.max(out1, out2)  # take strand with highest binding score\n",
    "\n",
    "        return out\n",
    "\n"
   ],
   "id": "ccf7698d4800b1c8",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### IV. Hyperparameter Search and Calibration Phase\n",
    "\n",
    "This block conducts a randomized hyperparameter search to identify the best-performing DeepBind model configuration. It performs the following:\n",
    "\n",
    "- Randomly samples values for hyperparameters such as dropout rate, learning rate, momentum, initialization noise, and regularization strengths.\n",
    "- Trains the model for multiple folds (3-fold cross-validation) and evaluates performance using Area Under the Curve (AUC).\n",
    "- Stores the best combination of hyperparameters that yields the highest average AUC across folds.\n",
    "- Saves the optimal settings in a `.pth` file for later use in final model training.\n",
    "\n",
    "This phase is essential for tuning the model to avoid overfitting or underfitting and to achieve robust motif prediction across diverse sequences.\n",
    "\n",
    "For each combination, the model is:\n",
    "\n",
    "\t1.\tInitialized and trained for up to 20000 steps.\n",
    "\t2.\tEvaluated every 4000 steps.\n",
    "\t3.\tTracked by validation AUC.\n",
    "\t4.\tCompared to previous best.\n",
    "\t5.\tIf it’s better → hyperparameters are saved."
   ],
   "id": "30ca65bceef07ed8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T10:43:52.632005Z",
     "start_time": "2025-06-20T10:32:32.791953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calibration Stage ;  Randomly sample different combinations of hyperparameters\n",
    "\n",
    "print(\"Using Apple MPS device\", device)\n",
    "# Hyper parameters - Default training configuration\n",
    "nummotif = 16 # Default Output Channel, number of motif filters to discover (Each one is intended to learn to recognize a different DNA motif)\n",
    "motiflen = 24 # Default Kernel size, the length of the motif to detect (filter width in the 1D convolution)\n",
    "\n",
    "def random_hyperparams_search(train_dataloader,valid_dataloader,device,nummotif=16,motiflen=24, num_trials=5):\n",
    "    learning_steps_list = [4000, 8000, 12000, 16000, 20000] # Predefined list of learning steps to evaluate\n",
    "    best_AUC = 0  # Initialize best AUC score\n",
    "    # Try 5 random hyperparameter combinations (Random Search over the hyperparameter space, instead of doing an exhaustive grid search (which is expensive))\n",
    "    for number in range(num_trials):\n",
    "\n",
    "        # Randomly select pooling type ('max' or 'maxavg')\n",
    "        pool_List = ['max', 'maxavg']\n",
    "        random_pool = random.choice(pool_List)\n",
    "\n",
    "        # Randomly select network type ('hidden' or 'nohidden')\n",
    "        neuType_list = ['hidden', 'nohidden']\n",
    "        random_neuType = random.choice(neuType_list)\n",
    "\n",
    "        # Randomly select dropout probability\n",
    "        dropoutList = [0.5, 0.75, 1.0]\n",
    "        dropprob = random.choice(dropoutList)\n",
    "\n",
    "        # Sample learning-related hyperparameters on log or sqrt scale\n",
    "        learning_rate = logsampler(0.0005, 0.05)\n",
    "        momentum_rate = sqrtsampler(0.95, 0.99)\n",
    "        sigmaConv = logsampler(1e-7, 1e-3)\n",
    "        sigmaNeu = logsampler(1e-5, 1e-2)\n",
    "\n",
    "        # Sample L2 regularization weights (beta1, beta2, beta3)\n",
    "        beta1 = logsampler(1e-15, 1e-3)\n",
    "        beta2 = logsampler(1e-10, 1e-3)\n",
    "        beta3 = logsampler(1e-10, 1e-3)\n",
    "\n",
    "        model_auc = [[], [], []]  # To store AUCs for each fold\n",
    "\n",
    "        # 3-fold cross-validation\n",
    "        for kk in range(3):\n",
    "            # Initialize a new model with current sampled hyperparameters\n",
    "            model = ConvNet(nummotif, motiflen, random_pool, random_neuType, 'training', dropprob,\n",
    "                            learning_rate, momentum_rate, sigmaConv, sigmaNeu,\n",
    "                            beta1, beta2, beta3, reverse_complemet_mode=reverse_mode).to(device)\n",
    "\n",
    "            # Create optimizer with appropriate parameters\n",
    "            if random_neuType == 'nohidden':\n",
    "                optimizer = torch.optim.SGD(\n",
    "                    [model.wConv, model.wRect, model.wNeu, model.wNeuBias],\n",
    "                    lr=model.learning_rate, momentum=model.momentum_rate, nesterov=True\n",
    "                )\n",
    "            else:\n",
    "                optimizer = torch.optim.SGD(\n",
    "                    [model.wConv, model.wRect, model.wNeu, model.wNeuBias, model.wHidden, model.wHiddenBias],\n",
    "                    lr=model.learning_rate, momentum=model.momentum_rate, nesterov=True\n",
    "                )\n",
    "\n",
    "            train_loader = train_dataloader[kk]\n",
    "            valid_loader = valid_dataloader[kk]\n",
    "            learning_steps = 0  # Reset training step counter\n",
    "\n",
    "            while learning_steps <= 20000:\n",
    "                model.mode = 'training'  # Set model to training mode\n",
    "\n",
    "                for i, (data, target) in enumerate(train_loader):\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "\n",
    "                    # If reverse mode is on, reduce label shape\n",
    "                    if model.reverse_complemet_mode:\n",
    "                        target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                        for i in range(target_2.shape[0]):\n",
    "                            target_2[i] = target[2*i] # the duplicated labels (forward + reverse) back into a single label\n",
    "                        target = target_2.to(device)\n",
    "\n",
    "                    output = model(data)  # Forward pass\n",
    "\n",
    "                    # Compute loss with L2 regularization\n",
    "                    if model.neuType == 'nohidden':\n",
    "                        loss = F.binary_cross_entropy(torch.sigmoid(output), target) + \\\n",
    "                               model.beta1 * model.wConv.norm() + \\\n",
    "                               model.beta3 * model.wNeu.norm()\n",
    "                    else:\n",
    "                        loss = F.binary_cross_entropy(torch.sigmoid(output), target) + \\\n",
    "                               model.beta1 * model.wConv.norm() + \\\n",
    "                               model.beta2 * model.wHidden.norm() + \\\n",
    "                               model.beta3 * model.wNeu.norm()\n",
    "                    # Backpropagation Step:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    learning_steps += 1\n",
    "\n",
    "                    # This mimics epoch-level validation AUC, but here it’s done every 4000 mini-batches instead.\n",
    "                    if learning_steps % 4000 == 0:\n",
    "                        with torch.no_grad():\n",
    "                            model.mode = 'test'\n",
    "                            auc = []\n",
    "                            for i, (data, target) in enumerate(valid_loader):\n",
    "                                data = data.to(device)\n",
    "                                target = target.to(device)\n",
    "\n",
    "                                if model.reverse_complemet_mode:\n",
    "                                    target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                                    for i in range(target_2.shape[0]):\n",
    "                                        target_2[i] = target[2*i]  # The duplicated labels (forward + reverse) back into a single label\n",
    "                                    target = target_2.to(device)\n",
    "\n",
    "                                output = model(data)\n",
    "                                pred_sig = torch.sigmoid(output)\n",
    "                                pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0]) #\n",
    "                                labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "                                auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "                            model_auc[kk].append(np.mean(auc))\n",
    "                            print('AUC performance when training fold number', kk+1,\n",
    "                                  'using', learning_steps_list[len(model_auc[kk])-1],\n",
    "                                  'learning steps =', np.mean(auc))\n",
    "\n",
    "        print('                   ##########################################               ')\n",
    "\n",
    "        # After evaluating all folds, track the best overall configuration\n",
    "        for n in range(5):\n",
    "            AUC = (model_auc[0][n] + model_auc[1][n] + model_auc[2][n]) / 3\n",
    "            if AUC > best_AUC:\n",
    "                best_AUC = AUC\n",
    "                best_learning_steps = learning_steps_list[n]\n",
    "                best_LearningRate = model.learning_rate\n",
    "                best_LearningMomentum = model.momentum_rate\n",
    "                best_neuType = model.neuType\n",
    "                best_poolType = model.poolType\n",
    "                best_sigmaConv = model.sigmaConv\n",
    "                best_dropprob = model.dropprob\n",
    "                best_sigmaNeu = model.sigmaNeu\n",
    "                best_beta1 = model.beta1\n",
    "                best_beta2 = model.beta2\n",
    "                best_beta3 = model.beta3\n",
    "\n",
    "    # Print and save the best hyperparameter configuration\n",
    "    print('best_poolType=', best_poolType)\n",
    "    print('best_neuType=', best_neuType)\n",
    "    print('best_AUC=', best_AUC)\n",
    "    print('best_learning_steps=', best_learning_steps)\n",
    "    print('best_LearningRate=', best_LearningRate)\n",
    "    print('best_LearningMomentum=', best_LearningMomentum)\n",
    "    print('best_sigmaConv=', best_sigmaConv)\n",
    "    print('best_dropprob=', best_dropprob)\n",
    "    print('best_sigmaNeu=', best_sigmaNeu)\n",
    "    print('best_beta1=', best_beta1)\n",
    "    print('best_beta2=', best_beta2)\n",
    "    print('best_beta3=', best_beta3)\n",
    "\n",
    "    # Save the best configuration to file for later training use\n",
    "    best_hyperparameters = {\n",
    "        'best_poolType': best_poolType,\n",
    "        'best_neuType': best_neuType,\n",
    "        'best_learning_steps': best_learning_steps,\n",
    "        'best_LearningRate': best_LearningRate,\n",
    "        'best_LearningMomentum': best_LearningMomentum,\n",
    "        'best_sigmaConv': best_sigmaConv,\n",
    "        'best_dropprob': best_dropprob,\n",
    "        'best_sigmaNeu': best_sigmaNeu,\n",
    "        'best_beta1': best_beta1,\n",
    "        'best_beta2': best_beta2,\n",
    "        'best_beta3': best_beta3\n",
    "    }\n",
    "\n",
    "    torch.save(best_hyperparameters, f\"best_hyperpamarameters_{nummotif}_{motiflen}.pth\")\n",
    "best_params = random_hyperparams_search(train_dataloader,valid_dataloader,device,nummotif=16,motiflen=24, num_trials=5)"
   ],
   "id": "646c74a94ade4cf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS device mps\n",
      "AUC performance when training fold number 1 using 4000 learning steps = 0.8226815392334564\n",
      "AUC performance when training fold number 1 using 8000 learning steps = 0.8211621302577231\n",
      "AUC performance when training fold number 1 using 12000 learning steps = 0.817389082252391\n",
      "AUC performance when training fold number 1 using 16000 learning steps = 0.8183264098524595\n",
      "AUC performance when training fold number 1 using 20000 learning steps = 0.8179476765629444\n",
      "AUC performance when training fold number 2 using 4000 learning steps = 0.8321437840564156\n",
      "AUC performance when training fold number 2 using 8000 learning steps = 0.8235438349040096\n",
      "AUC performance when training fold number 2 using 12000 learning steps = 0.8185642900951471\n",
      "AUC performance when training fold number 2 using 16000 learning steps = 0.8194135655296311\n",
      "AUC performance when training fold number 2 using 20000 learning steps = 0.8164297565120023\n",
      "AUC performance when training fold number 3 using 4000 learning steps = 0.8357009015917942\n",
      "AUC performance when training fold number 3 using 8000 learning steps = 0.8238604875959961\n",
      "AUC performance when training fold number 3 using 12000 learning steps = 0.8232763469459743\n",
      "AUC performance when training fold number 3 using 16000 learning steps = 0.8221433527321281\n",
      "AUC performance when training fold number 3 using 20000 learning steps = 0.820242887063326\n",
      "                   ##########################################               \n",
      "AUC performance when training fold number 1 using 4000 learning steps = 0.8324514524938786\n",
      "AUC performance when training fold number 1 using 8000 learning steps = 0.8202113554513825\n",
      "AUC performance when training fold number 1 using 12000 learning steps = 0.8193646474536821\n",
      "AUC performance when training fold number 1 using 16000 learning steps = 0.8103802724515254\n",
      "AUC performance when training fold number 1 using 20000 learning steps = 0.8019218852061304\n",
      "AUC performance when training fold number 2 using 4000 learning steps = 0.8242847575735193\n",
      "AUC performance when training fold number 2 using 8000 learning steps = 0.8126162212363345\n",
      "AUC performance when training fold number 2 using 12000 learning steps = 0.8064257160280133\n",
      "AUC performance when training fold number 2 using 16000 learning steps = 0.8012843759483415\n",
      "AUC performance when training fold number 2 using 20000 learning steps = 0.8037121521635779\n",
      "AUC performance when training fold number 3 using 4000 learning steps = 0.8252083652434591\n",
      "AUC performance when training fold number 3 using 8000 learning steps = 0.8191363244376474\n",
      "AUC performance when training fold number 3 using 12000 learning steps = 0.8157414551266053\n",
      "AUC performance when training fold number 3 using 16000 learning steps = 0.8091977479427136\n",
      "AUC performance when training fold number 3 using 20000 learning steps = 0.807263565860795\n",
      "                   ##########################################               \n",
      "AUC performance when training fold number 1 using 4000 learning steps = 0.8207232916248595\n",
      "AUC performance when training fold number 1 using 8000 learning steps = 0.8261645635501405\n",
      "AUC performance when training fold number 1 using 12000 learning steps = 0.8192611489919581\n",
      "AUC performance when training fold number 1 using 16000 learning steps = 0.8215582295936349\n",
      "AUC performance when training fold number 1 using 20000 learning steps = 0.817056949765862\n",
      "AUC performance when training fold number 2 using 4000 learning steps = 0.8274515421704055\n",
      "AUC performance when training fold number 2 using 8000 learning steps = 0.8257983958220808\n",
      "AUC performance when training fold number 2 using 12000 learning steps = 0.8260176231264319\n",
      "AUC performance when training fold number 2 using 16000 learning steps = 0.8246849238322027\n",
      "AUC performance when training fold number 2 using 20000 learning steps = 0.8231442453822462\n",
      "AUC performance when training fold number 3 using 4000 learning steps = 0.8205827181566323\n",
      "AUC performance when training fold number 3 using 8000 learning steps = 0.8186198540620423\n",
      "AUC performance when training fold number 3 using 12000 learning steps = 0.8149630628739429\n",
      "AUC performance when training fold number 3 using 16000 learning steps = 0.8110545667111164\n",
      "AUC performance when training fold number 3 using 20000 learning steps = 0.8073976946290252\n",
      "                   ##########################################               \n",
      "AUC performance when training fold number 1 using 4000 learning steps = 0.83456895868594\n",
      "AUC performance when training fold number 1 using 8000 learning steps = 0.8337106431463965\n",
      "AUC performance when training fold number 1 using 12000 learning steps = 0.8338859311696667\n",
      "AUC performance when training fold number 1 using 16000 learning steps = 0.8217941797778664\n",
      "AUC performance when training fold number 1 using 20000 learning steps = 0.8234932221637121\n",
      "AUC performance when training fold number 2 using 4000 learning steps = 0.8233413346661853\n",
      "AUC performance when training fold number 2 using 8000 learning steps = 0.810732321702476\n",
      "AUC performance when training fold number 2 using 12000 learning steps = 0.8116375240152383\n",
      "AUC performance when training fold number 2 using 16000 learning steps = 0.8046999469687185\n",
      "AUC performance when training fold number 2 using 20000 learning steps = 0.8123884715050691\n",
      "AUC performance when training fold number 3 using 4000 learning steps = 0.8330365699620351\n",
      "AUC performance when training fold number 3 using 8000 learning steps = 0.8300242184084279\n",
      "AUC performance when training fold number 3 using 12000 learning steps = 0.8191167071924612\n",
      "AUC performance when training fold number 3 using 16000 learning steps = 0.8151675461700826\n",
      "AUC performance when training fold number 3 using 20000 learning steps = 0.8211764247265739\n",
      "                   ##########################################               \n",
      "AUC performance when training fold number 1 using 4000 learning steps = 0.7315914238939766\n",
      "AUC performance when training fold number 1 using 8000 learning steps = 0.7685365501376173\n",
      "AUC performance when training fold number 1 using 12000 learning steps = 0.8302782884059552\n",
      "AUC performance when training fold number 1 using 16000 learning steps = 0.8356203720872096\n",
      "AUC performance when training fold number 1 using 20000 learning steps = 0.8326933568997659\n",
      "AUC performance when training fold number 2 using 4000 learning steps = 0.7197514120540788\n",
      "AUC performance when training fold number 2 using 8000 learning steps = 0.7477202873033042\n",
      "AUC performance when training fold number 2 using 12000 learning steps = 0.8256822373064163\n",
      "AUC performance when training fold number 2 using 16000 learning steps = 0.8329212766394017\n",
      "AUC performance when training fold number 2 using 20000 learning steps = 0.8303213788558488\n",
      "AUC performance when training fold number 3 using 4000 learning steps = 0.7235477021816951\n",
      "AUC performance when training fold number 3 using 8000 learning steps = 0.7508825952261181\n",
      "AUC performance when training fold number 3 using 12000 learning steps = 0.7839131288688562\n",
      "AUC performance when training fold number 3 using 16000 learning steps = 0.8352186360039495\n",
      "AUC performance when training fold number 3 using 20000 learning steps = 0.8364526062446985\n",
      "                   ##########################################               \n",
      "best_poolType= maxavg\n",
      "best_neuType= nohidden\n",
      "best_AUC= 0.8345867615768535\n",
      "best_learning_steps= 16000\n",
      "best_LearningRate= 0.0012620740423685529\n",
      "best_LearningMomentum= 0.9523500049979549\n",
      "best_sigmaConv= 3.319193122521004e-06\n",
      "best_dropprob= 0.75\n",
      "best_sigmaNeu= 5.8227772376079656e-05\n",
      "best_beta1= 2.2189355764608703e-14\n",
      "best_beta2= 1.6839181215356264e-06\n",
      "best_beta3= 8.965885372131983e-07\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### V. Final Training on Full Dataset with Best Hyperparameters\n",
    "\n",
    "In this section, I load the best hyperparameter configuration identified during the tuning phase and retrain the DeepBind model on the full dataset. Specifically:\n",
    "\n",
    "- I instantiate six models (`range(6)`) using the same optimized settings to increase the chance of capturing a robust training outcome due to the stochastic nature of initialization.\n",
    "- For each model, training is performed using the full dataset (`full_loader`) up to the best number of learning steps.\n",
    "- After training, each model is evaluated on the full dataset, and AUC is used as the selection metric.\n",
    "- The best-performing model (highest AUC) is saved to path (`MyModel_2_2.pth`) for final testing and interpretation.\n",
    "\n",
    "This stage ensures that the final model used for prediction has been trained under optimal conditions on all available data."
   ],
   "id": "e5b9cdcf18b501d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:50:36.416109Z",
     "start_time": "2025-06-20T11:47:30.681686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pick the best configuration (i.e., the best combination of the above) and train the model on full training data using that setting.\n",
    "def train_full_dataset_best_params(full_loader,nummotif,motiflen,device):\n",
    "\n",
    "    # Load best hyperparameters found during tuning\n",
    "    best_hyperparameters = torch.load(f'best_hyperpamarameters_{nummotif}_{motiflen}.pth')\n",
    "    # Unpack the best hyperparameters\n",
    "    best_poolType = best_hyperparameters['best_poolType']\n",
    "    best_neuType = best_hyperparameters['best_neuType']\n",
    "    best_learning_steps = best_hyperparameters['best_learning_steps']\n",
    "    best_LearningRate = best_hyperparameters['best_LearningRate']\n",
    "    best_dropprob = best_hyperparameters['best_dropprob']\n",
    "    best_LearningMomentum = best_hyperparameters['best_LearningMomentum']\n",
    "    best_sigmaConv = best_hyperparameters['best_sigmaConv']\n",
    "    best_sigmaNeu = best_hyperparameters['best_sigmaNeu']\n",
    "    best_beta1 = best_hyperparameters['best_beta1']\n",
    "    best_beta2 = best_hyperparameters['best_beta2']\n",
    "    best_beta3 = best_hyperparameters['best_beta3']\n",
    "\n",
    "    best_AUC = 0  # Initialize best AUC to track best performing model\n",
    "    # Train and evaluate 6 models with the same best configuration\n",
    "    for number_models in range(6):\n",
    "\n",
    "        # Create model using best parameters\n",
    "        model = ConvNet(nummotif, motiflen, best_poolType, best_neuType, 'training',\n",
    "                        best_dropprob, best_LearningRate, best_LearningMomentum,\n",
    "                        best_sigmaConv, best_sigmaNeu,\n",
    "                        best_beta1, best_beta2, best_beta3,\n",
    "                        reverse_complemet_mode=False).to(device)\n",
    "\n",
    "        # Select optimizer based on architecture\n",
    "        if model.neuType == 'nohidden':\n",
    "            optimizer = torch.optim.SGD(\n",
    "                [model.wConv, model.wRect, model.wNeu, model.wNeuBias],\n",
    "                lr=model.learning_rate,\n",
    "                momentum=model.momentum_rate,\n",
    "                nesterov=True\n",
    "            )\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(\n",
    "                [model.wConv, model.wRect, model.wNeu, model.wNeuBias,\n",
    "                 model.wHidden, model.wHiddenBias],\n",
    "                lr=model.learning_rate,\n",
    "                momentum=model.momentum_rate,\n",
    "                nesterov=True\n",
    "            )\n",
    "\n",
    "        train_loader = full_loader  # Use full dataset for training\n",
    "        valid_loader = full_loader  # Evaluate on full dataset as a proxy\n",
    "        learning_steps = 0\n",
    "\n",
    "        # Training loop\n",
    "        while learning_steps <= best_learning_steps:\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                # Handle reverse complement if enabled (not used here)\n",
    "                if model.reverse_complemet_mode:\n",
    "                    target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                    for i in range(target_2.shape[0]):\n",
    "                        target_2[i] = target[2*i]\n",
    "                    target = target_2.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "\n",
    "                # Compute loss with L2 regularization\n",
    "                if model.neuType == 'nohidden':\n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + \\\n",
    "                           model.beta1 * model.wConv.norm() + \\\n",
    "                           model.beta3 * model.wNeu.norm()\n",
    "                else:\n",
    "                    loss = F.binary_cross_entropy(torch.sigmoid(output), target) + \\\n",
    "                           model.beta1 * model.wConv.norm() + \\\n",
    "                           model.beta2 * model.wHidden.norm() + \\\n",
    "                           model.beta3 * model.wNeu.norm()\n",
    "\n",
    "                # Backpropagation and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                learning_steps += 1\n",
    "\n",
    "        # Evaluation on full dataset\n",
    "        with torch.no_grad():\n",
    "            model.mode = 'test'\n",
    "            auc = []\n",
    "            for i, (data, target) in enumerate(valid_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                if model.reverse_complemet_mode:\n",
    "                    target_2 = torch.randn(int(target.shape[0]/2), 1)\n",
    "                    for i in range(target_2.shape[0]):\n",
    "                        target_2[i] = target[2*i]\n",
    "                    target = target_2.to(device)\n",
    "\n",
    "                # Forward pass and AUC calculation\n",
    "                output = model(data)\n",
    "                pred_sig = torch.sigmoid(output)\n",
    "                pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "                labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "                auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "            # Compute and print mean AUC across batches\n",
    "            AUC_training = np.mean(auc)\n",
    "            print('AUC for model', number_models, '=', AUC_training)\n",
    "\n",
    "            # Save model if it's the best so far\n",
    "            if AUC_training > best_AUC:\n",
    "                print(\"Saving current best model!\")\n",
    "                state = {\n",
    "                    'conv': model.wConv,\n",
    "                    'rect': model.wRect,\n",
    "                    'wNeu': model.wNeu,\n",
    "                    'wNeuBias': model.wNeuBias\n",
    "                }\n",
    "\n",
    "                if model.neuType == 'hidden':\n",
    "                    state['wHidden'] = model.wHidden\n",
    "                    state['wHiddenBias'] = model.wHiddenBias\n",
    "                torch.save(state, \"MyModel_2_2.pth\")\n",
    "                best_AUC = AUC_training\n",
    "    return best_AUC\n",
    "\n",
    "# Execute training on full dataset\n",
    "best_full_AUC = train_full_dataset_best_params(full_loader,nummotif,motiflen, device)\n",
    "print(f\"\\nBest AUC on full dataset: {best_full_AUC:.4f}\")"
   ],
   "id": "53d74240568c6016",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for model 0 = 0.8273687939208703\n",
      "Saving current best model!\n",
      "AUC for model 1 = 0.8471863317850725\n",
      "Saving current best model!\n",
      "AUC for model 2 = 0.8074944747946348\n",
      "AUC for model 3 = 0.8481415856436914\n",
      "Saving current best model!\n",
      "AUC for model 4 = 0.7987091099706392\n",
      "AUC for model 5 = 0.864931917637338\n",
      "Saving current best model!\n",
      "Best AUC on full dataset: 0.8649\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### VI. Model Reloading and Validation Evaluation\n",
    "\n",
    "This section loads the best-performing trained DeepBind model from disk and evaluates it on the validation set (which, in this implementation, is the full training set reused for evaluation). Specifically:\n",
    "\n",
    "- The model weights saved in `MyModel_2_2.pth` are reloaded.\n",
    "- A new model instance is created using the same architecture and hyperparameters.\n",
    "- The weights (`wConv`, `wHidden`, etc.) are manually restored from the checkpoint file.\n",
    "- The model is run in inference mode (`torch.no_grad()` + `mode='test'`).\n",
    "- Predictions are computed across all validation data.\n",
    "- The ROC AUC metric is used to quantify prediction quality.\n",
    "\n",
    "This ensures consistency between training and inference and allows for robust final validation of the model’s performance before testing on unseen data."
   ],
   "id": "783405d7cce7da88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:53:06.501045Z",
     "start_time": "2025-06-20T11:53:06.259325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the saved weights (conv filters, hidden layer, biases, etc.)\n",
    "checkpoint = torch.load('MyModel_2_2.pth')\n",
    "\n",
    "def eval_validset(valid_loader,nummotif, motiflen, device):\n",
    "    # Load best hyperparameters found during tuning\n",
    "    best_hyperparameters = torch.load(f'best_hyperpamarameters_{nummotif}_{motiflen}.pth')\n",
    "    # Unpack the best hyperparameters\n",
    "    best_poolType = best_hyperparameters['best_poolType']\n",
    "    best_neuType = best_hyperparameters['best_neuType']\n",
    "    best_learning_steps = best_hyperparameters['best_learning_steps']\n",
    "    best_LearningRate = best_hyperparameters['best_LearningRate']\n",
    "    best_dropprob = best_hyperparameters['best_dropprob']\n",
    "    best_LearningMomentum = best_hyperparameters['best_LearningMomentum']\n",
    "    best_sigmaConv = best_hyperparameters['best_sigmaConv']\n",
    "    best_sigmaNeu = best_hyperparameters['best_sigmaNeu']\n",
    "    best_beta1 = best_hyperparameters['best_beta1']\n",
    "    best_beta2 = best_hyperparameters['best_beta2']\n",
    "    best_beta3 = best_hyperparameters['best_beta3']\n",
    "\n",
    "    # Recreate the exact same model structure with 'test' mode (no dropout)\n",
    "    model = ConvNet(\n",
    "        nummotif, motiflen, best_poolType, best_neuType, 'test',\n",
    "        best_LearningRate, best_LearningMomentum, best_sigmaConv,\n",
    "        best_dropprob, best_sigmaNeu,\n",
    "        best_beta1, best_beta2, best_beta3,\n",
    "        reverse_complemet_mode=reverse_mode  # use same reverse mode as training\n",
    "    ).to(device)\n",
    "\n",
    "    # Manually restore the weights from checkpoint (PyTorch manual param loading)\n",
    "    model.wConv = checkpoint['conv']\n",
    "    model.wRect = checkpoint['rect']\n",
    "    # model.wHidden = checkpoint['wHidden']\n",
    "    # model.wHiddenBias = checkpoint['wHiddenBias']\n",
    "    model.wNeu = checkpoint['wNeu']\n",
    "    model.wNeuBias = checkpoint['wNeuBias']\n",
    "\n",
    "    # Inference (no gradients needed)\n",
    "    with torch.no_grad():\n",
    "        model.mode = 'test'  # explicitly set model mode to 'test' (affects dropout)\n",
    "\n",
    "        auc = []  # list to collect AUC scores from all batches\n",
    "\n",
    "        # Iterate through the validation loader (previously built from full data)\n",
    "        for i, (data, target) in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # If reverse complement mode is on, merge duplicate labels\n",
    "            if model.reverse_complemet_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0] / 2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2 * i]\n",
    "                target = target_2.to(device)\n",
    "\n",
    "            # Forward pass: generate model predictions\n",
    "            output = model(data)\n",
    "\n",
    "            # Apply sigmoid to get probability predictions (from raw logits)\n",
    "            pred_sig = torch.sigmoid(output)\n",
    "\n",
    "            # Move predictions to CPU, detach from graph, convert to NumPy and flatten\n",
    "            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "\n",
    "            # Do the same for labels\n",
    "            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "            # Compute ROC AUC for this batch and add to the list\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "\n",
    "        # Compute final average AUC across all batches\n",
    "        AUC_training = np.mean(auc)\n",
    "        print(AUC_training)  # Display the final validation AUC\n",
    "\n",
    "eval_validset(full_loader,nummotif, motiflen, device)"
   ],
   "id": "8d101c4a7974e528",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864931917637338\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### VII. Final Model Evaluation on Completely Independent Test Set\n",
    "\n",
    "In this section, the best DeepBind model is evaluated on a held-out **test dataset** to assess its generalization ability. The steps are:\n",
    "\n",
    "- Load test sequences and labels from a separate `.gz` file using the `ChIP_exp` utility.\n",
    "- Apply the same preprocessing and encoding (including reverse complement handling if enabled).\n",
    "- Load the test data into a PyTorch `DataLoader` for batch-wise inference.\n",
    "- Perform a forward pass for predictions using the already trained and restored DeepBind model.\n",
    "- Apply `sigmoid()` to convert raw logits to probabilities.\n",
    "- Calculate the **ROC AUC score** on the entire test set to quantify model performance on unseen data.\n",
    "\n",
    "This final step provides a reliable estimate of how well the model will perform in real-world, unseen scenarios."
   ],
   "id": "4992bd8beadacace"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:01:00.567983Z",
     "start_time": "2025-06-20T12:01:00.360560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load test ChIP-seq dataset (Stanford_B replicate)\n",
    "chipseq_test = ChIP_exp(\"encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_B.seq.gz\")\n",
    "\n",
    "# Preprocess and padding with one-hot encode test sequences\n",
    "test_data = chipseq_test.openFile_test()\n",
    "\n",
    "# Wrap test data into custom PyTorch Dataset\n",
    "test_dataset = chipseq_dataset(test_data)\n",
    "\n",
    "# Use entire test set as a single batch (no shuffling, full batch size)\n",
    "batchSize = test_dataset.__len__()\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "def eval_independent_test_set(test_loader,nummotif, motiflen, device):\n",
    "        # Load best hyperparameters found during tuning\n",
    "    best_hyperparameters = torch.load(f'best_hyperpamarameters_{nummotif}_{motiflen}.pth')\n",
    "    # Unpack the best hyperparameters\n",
    "    best_poolType = best_hyperparameters['best_poolType']\n",
    "    best_neuType = best_hyperparameters['best_neuType']\n",
    "    best_learning_steps = best_hyperparameters['best_learning_steps']\n",
    "    best_LearningRate = best_hyperparameters['best_LearningRate']\n",
    "    best_dropprob = best_hyperparameters['best_dropprob']\n",
    "    best_LearningMomentum = best_hyperparameters['best_LearningMomentum']\n",
    "    best_sigmaConv = best_hyperparameters['best_sigmaConv']\n",
    "    best_sigmaNeu = best_hyperparameters['best_sigmaNeu']\n",
    "    best_beta1 = best_hyperparameters['best_beta1']\n",
    "    best_beta2 = best_hyperparameters['best_beta2']\n",
    "    best_beta3 = best_hyperparameters['best_beta3']\n",
    "\n",
    "    # Recreate the exact same model structure with 'test' mode (no dropout)\n",
    "    model = ConvNet(\n",
    "        nummotif, motiflen, best_poolType, best_neuType, 'test',\n",
    "        best_LearningRate, best_LearningMomentum, best_sigmaConv,\n",
    "        best_dropprob, best_sigmaNeu,\n",
    "        best_beta1, best_beta2, best_beta3,\n",
    "        reverse_complemet_mode=reverse_mode  # use same reverse mode as training\n",
    "    ).to(device)\n",
    "\n",
    "    # Manually restore the weights from checkpoint (PyTorch manual param loading)\n",
    "    model.wConv = checkpoint['conv']\n",
    "    model.wRect = checkpoint['rect']\n",
    "    # model.wHidden = checkpoint['wHidden']\n",
    "    # model.wHiddenBias = checkpoint['wHiddenBias']\n",
    "    model.wNeu = checkpoint['wNeu']\n",
    "    model.wNeuBias = checkpoint['wNeuBias']\n",
    "\n",
    "    # Evaluation: No gradient tracking required\n",
    "    with torch.no_grad():\n",
    "        model.mode = 'test'  # Ensure model behaves deterministically (no dropout)\n",
    "\n",
    "        auc = []  # List to store AUC for this test batch\n",
    "        auprc = []\n",
    "        # Iterate through the test DataLoader (only one batch expected)\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Adjust labels if reverse complement mode is enabled\n",
    "            if model.reverse_complemet_mode:\n",
    "                target_2 = torch.randn(int(target.shape[0] / 2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i] = target[2 * i]\n",
    "                target = target_2.to(device)\n",
    "            output = model(data)\n",
    "            pred_sig = torch.sigmoid(output)\n",
    "            pred = pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels = target.cpu().numpy().reshape(output.shape[0])\n",
    "\n",
    "            # Compute ROC AUC score for this batch and append to list\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "            auprc.append(metrics.average_precision_score(labels, pred))\n",
    "        # Compute final average AUC across batches (only one here)\n",
    "        AUC_training = np.mean(auc)\n",
    "        print(f\"For {nummotif} motif filters and {motiflen} bp kernel size;\")\n",
    "        print(f\"AUC on test data = {np.mean(auc):.3f}, \\nAUPRC on test data= {np.mean(auprc):.3f}\")\n",
    "    return labels,pred\n",
    "labels, pred  = eval_independent_test_set(test_loader,nummotif, motiflen, device)"
   ],
   "id": "8a258f4a3aaee6ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 16 motif filters and 24 bp kernel size;\n",
      "AUC on test data = 0.937, \n",
      "AUPRC on test data= 0.943\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ROC Curves",
   "id": "591aac43f9b0d305"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:02:10.316066Z",
     "start_time": "2025-06-20T12:02:10.245559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(labels, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "bd705e79bd2e4ba8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:02:12.825142Z",
     "start_time": "2025-06-20T12:02:12.779588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "precision, recall, _ = metrics.precision_recall_curve(labels, pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.plot(recall, precision, label=f\"AUPRC = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "efc2c172dec37dd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50d253812bb375df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
